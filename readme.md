# Chroniqueur de Runeterra : Un Agent RAG sur l'univers de League of Legends

Ce projet impl√©mente un agent conversationnel avanc√© bas√© sur une architecture RAG (Retrieval-Augmented Generation). Le "Chroniqueur de Runeterra" est un chatbot sp√©cialis√© dans le lore de l'univers du jeu vid√©o *League of Legends*. Il est capable de r√©pondre √† des questions pr√©cises sur les champions et les r√©gions en se basant sur une base de connaissances construite √† partir de sources officielles.

## Demo

Une version live de l'application est d√©ploy√©e ici : [**lo17.raphcvr.me**](https://lo17.raphcvr.me/)


## ‚ú® Fonctionnalit√©s

  - **Interface de Chat intuitive** : Une application Streamlit permet aux utilisateurs de dialoguer en langage naturel avec l'assistant.
  - **Base de Connaissances Automatis√©e** : Un script de scraping (`data_scrapper.py`) collecte automatiquement le lore depuis des sources de confiance (wiki Fandom, League of Legends Universe).
  - **Base de Donn√©es Vectorielle** : Utilisation de **ChromaDB** pour stocker et rechercher efficacement les documents de lore gr√¢ce √† des embeddings s√©mantiques.
  - **Transformation de Requ√™te Avanc√©e** : Le syst√®me utilise un LLM pour analyser la conversation et transformer la question de l'utilisateur en requ√™tes optimis√©es pour la recherche vectorielle, am√©liorant ainsi la pertinence des r√©sultats.
  - **Transparence des Sources** : Pour chaque r√©ponse, l'assistant cite les documents qu'il a utilis√©s, permettant √† l'utilisateur de v√©rifier l'information √† la source.
  - **√âvaluation Rigoureuse** : Le projet inclut un framework d'√©valuation (`evaluation.py`) utilisant la biblioth√®que `ragas` pour mesurer la fid√©lit√© (`Faithfulness`) et la correction (`Correctness`) des r√©ponses g√©n√©r√©es.
  - **G√©n√©ration de Donn√©es de Test** : Un script (`generate_testset.py`) permet de cr√©er un jeu de donn√©es d'√©valuation synth√©tique de haute qualit√© pour valider la performance du RAG.
  - **Pr√™t pour le D√©ploiement** : L'application est enti√®rement conteneurisable et fournie avec une configuration Kubernetes (`k8s-lo17-rag-app.yaml`) pour un d√©ploiement cloud-native.

## üèõÔ∏è Architecture

Le workflow de l'application suit les √©tapes classiques d'un pipeline RAG moderne :

1.  **Interface Utilisateur (Streamlit)** : L'utilisateur saisit sa question dans l'interface de chat.
2.  **Transformation de la Requ√™te (`inference.py`)** : Un premier appel au LLM (Google Gemini) analyse la question dans le contexte de la conversation et g√©n√®re des requ√™tes de recherche s√©mantique optimis√©es.
3.  **R√©cup√©ration d'Information (`rag_core.py`)** : Les requ√™tes optimis√©es sont utilis√©es pour interroger la base de donn√©es vectorielle ChromaDB. Les documents les plus pertinents sont r√©cup√©r√©s.
4.  **Augmentation du Contexte** : Les documents r√©cup√©r√©s sont inject√©s dans le contexte d'un nouveau prompt.
5.  **G√©n√©ration de la R√©ponse (`inference.py`)** : Le prompt augment√© est envoy√© au LLM, qui a pour instruction d'agir comme le "Chroniqueur de Runeterra" et de synth√©tiser une r√©ponse en se basant *uniquement* sur les documents fournis.
6.  **Affichage en Streaming (Streamlit)** : La r√©ponse est affich√©e en temps r√©el dans l'interface, et les sources sont list√©es dans un menu d√©roulant pour la transparence.

## üóÇÔ∏è Structure du Projet

```
.
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ config.toml           # Th√®me et configuration de l'interface Streamlit
‚îú‚îÄ‚îÄ dataset_rag_lol_definitive/
‚îÇ   ‚îú‚îÄ‚îÄ knowledge_base/       # (G√©n√©r√©) Contient les .txt du lore scrap√©
‚îÇ   ‚îî‚îÄ‚îÄ synthetic_evaluation.csv # (G√©n√©r√©) Jeu de donn√©es pour l'√©valuation
‚îú‚îÄ‚îÄ app.py                      # Script CLI simple pour tester le RAG
‚îú‚îÄ‚îÄ create_database.py          # Script pour construire la base de donn√©es ChromaDB
‚îú‚îÄ‚îÄ data_scrapper.py            # Script pour scraper le lore et cr√©er la base de connaissance
‚îú‚îÄ‚îÄ evaluation.py               # Script pour √©valuer le RAG avec Ragas
‚îú‚îÄ‚îÄ generate_testset.py         # Script pour g√©n√©rer le jeu de donn√©es d'√©valuation
‚îú‚îÄ‚îÄ inference.py                # Logique d'inf√©rence du chatbot
‚îú‚îÄ‚îÄ k8s-lo17-rag-app.yaml       # Fichier de d√©ploiement Kubernetes
‚îú‚îÄ‚îÄ rag_core.py                 # C≈ìur du syst√®me RAG (connexion DB, query, mod√®les)
‚îú‚îÄ‚îÄ streamlit_app.py            # Application principale Streamlit
‚îú‚îÄ‚îÄ pyproject.toml              # D√©pendances et configuration du projet
‚îî‚îÄ‚îÄ ...
```

## üöÄ Installation et Lancement Local

Vous avez deux options pour installer et lancer le projet localement :

1.  **Avec le Lanceur PowerShell (Recommand√© pour Windows)** : Un script `launch.ps1` est fourni pour automatiser l'ensemble du processus.
2.  **Manuellement** : Suivez les √©tapes ci-dessous si vous n'√™tes pas sur Windows ou si vous pr√©f√©rez une installation manuelle.

### Option 1 : Utilisation du Lanceur PowerShell (Windows)

Le script `launch.ps1` simplifie grandement l'installation et la gestion du projet.

1.  **T√©l√©charger le lanceur** :
    *   T√©l√©chargez le fichier `launch.ps1` depuis le d√©p√¥t GitHub (vous pouvez le trouver √† la racine du projet).
    *   Placez-le dans un dossier de votre choix.

2.  **Ex√©cuter le script** :
    *   Ouvrez une console PowerShell.
    *   Naviguez jusqu'au dossier o√π vous avez plac√© `launch.ps1`.
    *   Ex√©cutez la commande suivante (vous pourriez avoir besoin d'ajuster votre politique d'ex√©cution PowerShell si ce n'est pas d√©j√† fait : `Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass -Force`) :
        ```powershell
        .\launch.ps1
        ```

3.  **Suivre les instructions du menu** :
    Le script vous pr√©sentera un menu interactif :
    *   **Option 1 : Installation et Configuration Compl√®te**
        *   T√©l√©charge la derni√®re version du projet depuis GitHub.
        *   Vous guide pour configurer vos cl√©s API Google et OpenAI (qui seront stock√©es dans un fichier `.env`). La cl√© OpenAI est n√©cessaire si vous souhaitez utiliser l'option 4.
        *   Installe toutes les d√©pendances Python n√©cessaires avec `uv`.
        *   Construit la base de connaissances en ex√©cutant le scraping des donn√©es (`data_scrapper.py`) et la cr√©ation de la base de donn√©es vectorielle (`create_database.py`).
    *   **Option 2 : Lancer l'application Streamlit (le site)**
        *   D√©marre l'application web Streamlit. Accessible ensuite via `http://localhost:8501`.
        *   N√©cessite que l'installation (Option 1) ait √©t√© compl√©t√©e au pr√©alable.
    *   **Option 3 : Lancer l'√©valuation du syst√®me RAG**
        *   Ex√©cute le script d'√©valuation (`evaluation.py`).
        *   N√©cessite que l'installation (Option 1) ait √©t√© compl√©t√©e et que le jeu de donn√©es d'√©valuation (`synthetic_evaluation.csv`) soit pr√©sent (g√©n√©r√© via l'option 1 ou l'option 4).
    *   **Option 4 : G√©n√©rer le jeu de donn√©es d'√©valuation**
        *   Ex√©cute le script `generate_testset.py` pour cr√©er `synthetic_evaluation.csv`.
        *   N√©cessite que l'installation (Option 1) ait √©t√© compl√©t√©e (pour la base de connaissances) et que la cl√© `OPENAI_API_KEY` soit configur√©e dans le fichier `.env`.
    *   **Option 5 : Quitter**

    Le script s'assure √©galement que `uv` est install√© sur votre syst√®me, et l'installe si ce n'est pas le cas.

### Option 2 : Installation Manuelle

Suivez ces √©tapes pour lancer l'application sur votre machine.

### Pr√©requis

  - Python 3.12+
  - Un gestionnaire de paquets comme `pip` ou `uv`.

### 1\. Cloner le D√©p√¥t (si non fait par le script PowerShell)

```bash
git clone https://github.com/Ryustel/LO17ProjetRAG.git
cd LO17ProjetRAG
```

### 2\. Installer les D√©pendances (si non fait par le script PowerShell)

Il est recommand√© d'utiliser un environnement virtuel √† l'aide d'uv ([**Installation d'uv**](https://docs.astral.sh/uv/getting-started/installation/)

Installez les d√©pendances list√©es dans `pyproject.toml` :

```bash
uv sync
```

### 3\. Configurer les Cl√©s d'API (si non fait par le script PowerShell)

Cr√©ez un fichier `.env` √† la racine du projet et ajoutez vos cl√©s d'API. Le projet utilise les mod√®les de Google pour le RAG et potentiellement OpenAI pour la g√©n√©ration du jeu de test.

```env
# .env
GOOGLE_API_KEY="VOTRE_CLE_API_GOOGLE"
OPENAI_API_KEY="VOTRE_CLE_API_OPENAI" # Optionnelle, pour cr√©er un jeu de test
```

### 4\. Construire la Base de Connaissances (si non fait par le script PowerShell)

Ces scripts doivent √™tre ex√©cut√©s dans l'ordre.

```bash
# 1. Scraper les donn√©es du web
uv run data_scrapper.py

# 2. Construire la base de donn√©es vectorielle
uv run create_database.py
```

√Ä la fin de cette √©tape, vous devriez avoir un dossier `database/chroma_db` peupl√©.

### 5\. Lancer l'Application Streamlit

```bash
uv run streamlit run streamlit_app.py
```

L'application devrait √™tre accessible √† l'adresse `http://localhost:8501`.

## üìä √âvaluation du Syst√®me

Le projet est dot√© d'un syst√®me d'√©valuation pour mesurer la qualit√© des r√©ponses.

1.  **G√©n√©rer le jeu de test (Optionnel)** :
    Le script `generate_testset.py` utilise un LLM (OpenAI par d√©faut) pour cr√©er des questions/r√©ponses pertinentes √† partir de la base de connaissances.

    ```bash
    python generate_testset.py
    ```

    Cela cr√©era le fichier `dataset_rag_lol_definitive/synthetic_evaluation.csv`.

2.  **Lancer l'√©valuation** :
    Ce script utilise le fichier CSV g√©n√©r√© pour √©valuer le pipeline RAG sur les m√©triques de `faithfulness` et `answer_correctness`.

    ```bash
    python evaluation.py
    ```

    Les r√©sultats d√©taill√©s seront sauvegard√©s dans `evaluation_results.csv`.

## üì¶ D√©ploiement

Le fichier `k8s-lo17-rag-app.yaml` contient la configuration compl√®te pour un d√©ploiement sur un cluster Kubernetes.

Points cl√©s :

  - **Init Container** : Un conteneur d'initialisation se charge d'ex√©cuter `data_scrapper.py` et `create_database.py` au premier d√©marrage du pod.
  - **Persistance** : Un `PersistentVolumeClaim` est utilis√© pour que la base de donn√©es ChromaDB ne soit pas reconstruite √† chaque red√©marrage du pod.
  - **Secrets** : Les cl√©s d'API doivent √™tre fournies au cluster via des secrets Kubernetes (`google-api-secret`, `openai-api-secret`).
  - **Ingress** : Une r√®gle Ingress est d√©finie pour exposer le service Streamlit sur le web, par exemple via le domaine `lo17.raphcvr.me`.

## üõ†Ô∏è Technologies Utilis√©es

  - **Frontend** : Streamlit
  - **Backend & Orchestration** : Python, LangChain
  - **LLMs** : Google Gemini, OpenAI (pour la cr√©ation du jeu de test)
  - **Embeddings** : Google Generative AI Embeddings, OpenAI Embeddings (pour la cr√©ation du jeu de test)
  - **Base de Donn√©es Vectorielle** : ChromaDB
  - **Scraping** : BeautifulSoup, Requests
  - **√âvaluation RAG** : Ragas
  - **D√©ploiement** : Docker, Kubernetes